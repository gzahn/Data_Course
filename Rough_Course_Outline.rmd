---
output:
  pdf_document: default
  html_document: default
---
# **Data Analysis Course Outline**

**Below are the tentative weekly topics to be covered.**
**Also included are selected R functions that we will learn how to use.**

**Further, there are examples of some code and its output for each week**
**to give you an rough idea about what these topics are covering.**

**We will learn all of this as we go, so don't be scared by anything...it get pretty easy once you have a foundation.**

**This document was constructed entirely within R as an R-markdown (Rmd) file.**

The complete code for this document can be found online [HERE](https://raw.githubusercontent.com/gzahn/Data_Course/master/Rough_Course_Outline.rmd)

All course documents and data sets can be found on the [Course GitHub repository](https://github.com/gzahn/Data_Course)


---------------------------------------------------------------------------

### WEEK 1

* Why use code!?
* INSTALL R / R-studio
* Familiarize R-studio functions and layout
* Where to look for help

```{r eval=FALSE, include=TRUE}
# Functions covered (parital list):
help()
```

---------------------------------------------------------------------------
  
### WEEK 2

* Assigning things to objects
* Get familiar with object types and basic functions
    * values, vectors, lists
    * data frames and matrices
    * boolean, character, numeric, POSIXct  
* Accessing elements of objects
* Boolean evaluations
* Data-type conversions


```{r eval=FALSE, include=TRUE}
# Functions covered (parital list):
=       <-      ->
class()   
data.frame()  as.factor()   as.numeric()    as.character()    as.POSIXct()    as.matrix()
==    <   >   <=    >=
+     -   *   /     
which()   signif()    ceiling()     floor()       round()    
c()       list()      cbind()       rbind()       sum()         mean()        sd()        
```

```{r}
vector = c(1,2,3,4,5,6,7,8,9,10) # assign a series of numbers to an object called "vector"
mean(vector) # calculate the mean of the numbers in that object
```

---------------------------------------------------------------------------
  
### WEEK 3

* Importing data
* Useful data formats
* Data structure and attributes
* Summary stats and basic visualizations
* Exploring data
    * Sorting, Transposing, Sampling
    * heatmaps, boxplots, barcharts, scatterplots, histograms
    
```{r eval=FALSE, include=TRUE}
# Functions covered (parital list):
read.csv()        read.delim()
str()             dim()             names()           attributes()          head()          
summary()         min()             max()             range()               quantile()
hist()            boxplot()         barplot()         plot()                heatmap()
sample()          t()               sort()            tail()                var()
```

```{r echo=TRUE, fig.height=3,fig.width=4,fig.align='left'}
plot(co2, main = "[CO2] Time Series") # make a simple plot of the data in the object called "co2"
```

```{r}
summary(co2) # generate statistical summaries of those data
```

---------------------------------------------------------------------------
  
### WEEK 4

* Finding/Installing/Loading packages
* Extending functionality of R
* Subsetting and manipulating raw data
* Output options

```{r eval=FALSE, include=TRUE}
# Functions covered (parital list):
install.packages()      
library()
cor()
write.table()       sink()        tiff/jpeg/png() / dev.off()
```

```{r include=FALSE}
data = CO2[c(1,43,44,2,3,45,4,46,5,47),]
```

```{r}
data # show original data
```

```{r}
data[data$Type == "Quebec",] # subset data to only include samples from "Quebec"
```


      Skills Test 1:

      * Import data set
      * Convert elements to new data type
      * Subset based on values
      * Calculate summary statistics
      * Create basic summary figures
      * Export summary statistics to text file
  
---------------------------------------------------------------------------  

### WEEK 5

* Data estimations
    * point estimates
    * interval estimates
* Hypothesis testing / Model fitting
    * t-test (paired/unpaired)
    * chi-square
    * ANOVA
    * LM/GLM
<<<<<<< HEAD
    * Mixed-effect models (lme4)
=======
    * rpart
>>>>>>> b26891862de9aa2558f6ee907eaa18f7dfea92a5

```{r eval=FALSE, include=TRUE}
# Functions covered (parital list):
lm()        glm()         aov()
t.test()    chisq.test()  rpart()     gmodel()
```

```{r}
ANOVA = aov(uptake ~ conc, data = CO2) # define an analysis of variance model CO2 uptake by plants, predicted by CO2 concentration in atmosphere
summary(ANOVA) # show summary ANOVA table and P-value
```

---------------------------------------------------------------------------  

### WEEK 6

* Experimental design
* Common designs and analysis options
* Quantitative vs qualitative data
* Probability distributions
* Fitting distributions
* Type I and Type II errors
* Post-hoc tests

```{r eval=FALSE, include=TRUE}
# Packages used (partial list):
fitdistrplus
MASS
# Functions covered (parital list):
plotdist()      descdist()
fitdist()       denscomp()        cdfcomp()
TukeyHSD()      
```

```{r include=FALSE}
library(fitdistrplus)
```


```{r fig.height=3,fig.width=4}
# Fit CO2 uptake data from Quebec samples to a logistic probability distribution
fit.logistic = fitdist(CO2$uptake[CO2$Type == "Quebec"], distr = "logis") 
denscomp(fit.logistic) # Plot comparison between logistic distribution and actual data
```

---------------------------------------------------------------------------  

### WEEK 7

* Non-parametric alternatives
* Mann-Whitney-Wilcoxin
* Kruskal-Wallace
* Apply functions

```{r eval=FALSE, include=TRUE}
# Packages used (partial list):

# Functions covered (parital list):
wilcox.test()     kruskal.test()

apply()     sapply()      lapply()      tapply()
```

```{r}
data[,4:5] # look at columns 4 and 5 from object called "data"
apply(data[,4:5], 2, sum) # Apply the 'sum' function to those columns
```

---------------------------------------------------------------------------  

### WEEK 8

* Other peoples' data
* Principles of tidy data
* Intuitive manipulations and group functions
    * filter
    * arrange
    * select
    * mutate
    * group_by
    * summarize
    * %>%
* Tidy data transformations
    * gather
    * spread

```{r eval=FALSE, include=TRUE}
# Packages used (partial list):
dplr      plyr      tidyr
# Functions covered (parital list):
filter()      arrange()       select()        mutate()        
group_by()    summarize()     %>%
gather()      spread()
```

```{r include=FALSE}
library(dplyr)
```


```{r}
# Get specific summary data for defined groups from the object called "data" and save as object called "group.summaries"
group.summaries = data %>%
  group_by(Type) %>%
  summarize(Samples = n(), Mean.uptake = mean(uptake), Total.uptake = sum(uptake), StDev.uptake = sd(uptake))

as.data.frame(group.summaries) # display summary info for different locations (groups) as a data frame

```


      Skills Test 2: 	
      
      * Import messy data
      * Convert to tidy format
      * Plot data distribution
      * Rearrange and mutate data set
      * Summary stats on grouped data
      * Test hypothesis / post-hoc tests
    
---------------------------------------------------------------------------        

### WEEK 9
* Predicting data
* Intro to ggplot	

```{r eval=FALSE, include=TRUE}
# Packages used (partial list):
ggplot2

# Functions covered (parital list):
predict() 
qplot()
ggplot()
    aes()
```

```{r fig.height=3,fig.width=4}
library(ggplot2) # load ggplot2 package

new.data = data.frame(conc = c(1500,2000)) # give new predictor values (CO2 concentration)
predicted = predict(ANOVA, newdata = new.data) # predict plant uptake for those values based on previous ANOVA model ... see Week 5
predicted # Look at predictions based on our ANOVA model

plot(CO2$conc,CO2$uptake,xlim=c(0,2000),ylim=c(0,60)) # simple plot of CO2 data
points(x=c(1500,2000),y=predicted[1:2],pch=20,col="Red") # Add our predicted uptake values for higher CO2 concentrations in red
```
    
---------------------------------------------------------------------------  

### WEEK 10
* Figure generation
* Figure export

```{r eval=FALSE, include=TRUE}
# Packages used (partial list):
ggplot2

# Functions covered (parital list):
ggplot()
geom_point()      geom_boxplot()      geom_bar()      geom_violin()
labs()            ggsave()            
```

```{r fig.height=3,fig.width=7}
library(ggplot2) # load ggplot2 package

# Create ggplot and save as abject called "CO2.plot"
CO2.plot = ggplot(CO2, aes(x=conc, y=uptake, col=Type))+
  geom_point() +
  geom_smooth(method = "loess") + 
  labs(x="CO2 concentration in atmosphere", y="CO2 uptake by plants (uMol/s)") +
  ggtitle("CO2 uptake as a function of atmospheric CO2 concentration (ppm)") +
  theme_bw() +
  scale_color_discrete(name = "Location")

# Display plot
CO2.plot

```



---------------------------------------------------------------------------  

### WEEK 11
* Figure generation continued

```{r eval=FALSE, include=TRUE}
# Packages used (partial list):
ggplot2
gridExtra

# Functions covered (parital list):
grid.arrange()
ggplot()
scale_*()
```

```{r include=FALSE}
library(gridExtra)
```

```{r}
# Make two separate plots - One for each temperature treatment
CO2.plot.1 = ggplot(CO2[CO2$Treatment == "chilled",], aes(x=conc, y=uptake, col=Type)) +
  geom_point() +
  geom_smooth(method = "loess") +
  ggtitle("Chilled") +
  theme(legend.position="none")

CO2.plot.2 = ggplot(CO2[CO2$Treatment == "nonchilled",], aes(x=conc, y=uptake, col=Type)) +
  geom_point() +
  geom_smooth(method = "loess") +
  ggtitle("Non-Chilled") +
  theme(legend.position=c(.75,.25))

# Combine the two plots into one image
grid.arrange(CO2.plot.1, CO2.plot.2, nrow = 1)
```

---------------------------------------------------------------------------  

### WEEK 12
* Data standardization / normalization
* Ecology examples
    * Ordinations / NMDS
    * PermANOVA
    * Distance measures
    * Diversity measures

```{r eval=FALSE, include=TRUE}
# Packages used (partial list):
vegan

# Functions covered (parital list):
decostand()       rrarefy()         dist()        betadiver()         
metaMDS()         adonis()          diversity()   betadisper()
```
   
```{r include=FALSE}
library(vegan)
set.seed(55)

# Generate a random community matrix, similar to the type of data in an OTU Table
prob = c(0.99,rep(0.05,1000)) # sets probability of each number being randomly chosen

community_matrix=matrix(
  sample(0:1000,300,replace=T, prob = prob),nrow=10,
  dimnames=list(paste("Sample_",1:10,sep=""),paste("Species_",1:30,sep="")))

# Add a treatment vector, assigning samples to one of two groups
treat=c(rep("Treatment_1",5),rep("Treatment_2",5))
```
   
```{r}
head(community_matrix)[,1:10] # Take a look at the community composition (observed counts) for different samples
```

```{r fig.height=3,fig.width=4}
# Look at the beta diversity between two randomly-generated communities

beta_div = betadiver(community_matrix, method = "w")
beta_disp = betadisper(beta_div, treat)
plot(beta_disp)

```


   
      Skills Test 3:	
      
      * Import data set
      * Fit appropriate model
      * Use model to predict new response values from new predictors
      * Generate and export plots from data sets

---------------------------------------------------------------------------  

### WEEK 13

* Importing and manipulating DNA sequence data
    * Bioconductor
    * Sequence data
    * Biostrings
* Phylogenetics examples
    * Sequence alignment
    * Tree building
    * Taxonomic assignment

```{r eval=FALSE, include=TRUE}
# Packages used (partial list):
Bioconductor
ape
biostrings

# Functions covered (parital list):

To be decided...

```

```{r include=FALSE}
library(Biostrings)
library(ape)
library(msa)
```

```{r}
# Assign a DNA sequence to a special DNAString object
Seq_1 = DNAString("TCTCTTCGCCGCCGCTGGCCTTGCCGCTGCTGCTCCTCTCGAGTCTCGCCAGGACACCGCATCCTGCCCTGTCACCACTGAGGGTGACTACGTCTGG")

reverseComplement(Seq_1) # Gives reverse-compliment of a DNA sequence

```

---------------------------------------------------------------------------  

### WEEK 14

* Command-line tools
* BASH
* compression
* grep, sed, find, |, gzip/gunzip, tar, mv, cp, mkdir, etc.

---------------------------------------------------------------------------  

### WEEK 15
* Data management
* Reporting
* Rmd

      Skills Test 4 (final):
      
      * Command-line data access and manipulation
      * Writing a script to
          + import specific data
          + tidy and normalize data
          + subset and group
          + test hypotheses
          + create intuitive plots that include test statistics
      * Save script as readable report
      
---------------------------------------------------------------------------  

**This document was constructed entirely within R as an R-markdown (Rmd) file.**

The complete code for this document can be found online [HERE](https://raw.githubusercontent.com/gzahn/Data_Course/master/Rough_Course_Outline.rmd) at the [Course GitHub repository](https://github.com/gzahn/Data_Course)


---------------------------------------------------------------------------            
